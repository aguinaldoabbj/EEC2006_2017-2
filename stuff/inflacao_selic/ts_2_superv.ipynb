{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     pollution  dew  temp   press wnd_dir  wnd_spd  snow  rain\n",
      "date                                                                          \n",
      "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0      SE     1.79     0     0\n",
      "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0      SE     2.68     0     0\n",
      "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0      SE     3.57     0     0\n",
      "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0      SE     5.36     1     0\n",
      "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0      SE     6.25     2     0\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "# load data\n",
    "def parse(x):\n",
    "\treturn datetime.strptime(x, '%Y %m %d %H')\n",
    "dataset = read_csv('raw.csv',  parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)\n",
    "dataset.drop('No', axis=1, inplace=True)\n",
    "# manually specify column names\n",
    "dataset.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']\n",
    "dataset.index.name = 'date'\n",
    "# mark all NA values with 0\n",
    "dataset['pollution'].fillna(0, inplace=True)\n",
    "# drop the first 24 hours\n",
    "dataset = dataset[24:]\n",
    "# summarize first 5 rows\n",
    "print(dataset.head(5))\n",
    "# save to file\n",
    "dataset.to_csv('pollution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('STP-20171124170718044.csv')\n",
    "df.Data = pd.to_datetime(pd.Series(df.Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 12)\n",
      "(100, 9) 100 (100,)\n",
      "(100, 3, 3) (100,) (18, 3, 3) (18,)\n",
      "Train on 100 samples, validate on 18 samples\n",
      "Epoch 1/200\n",
      "1s - loss: 0.3719 - val_loss: 0.3697\n",
      "Epoch 2/200\n",
      "0s - loss: 0.3395 - val_loss: 0.3302\n",
      "Epoch 3/200\n",
      "0s - loss: 0.3086 - val_loss: 0.2912\n",
      "Epoch 4/200\n",
      "0s - loss: 0.2785 - val_loss: 0.2577\n",
      "Epoch 5/200\n",
      "0s - loss: 0.2501 - val_loss: 0.2300\n",
      "Epoch 6/200\n",
      "0s - loss: 0.2244 - val_loss: 0.2056\n",
      "Epoch 7/200\n",
      "0s - loss: 0.2025 - val_loss: 0.1894\n",
      "Epoch 8/200\n",
      "0s - loss: 0.1836 - val_loss: 0.1856\n",
      "Epoch 9/200\n",
      "0s - loss: 0.1665 - val_loss: 0.1858\n",
      "Epoch 10/200\n",
      "0s - loss: 0.1531 - val_loss: 0.1942\n",
      "Epoch 11/200\n",
      "0s - loss: 0.1456 - val_loss: 0.2060\n",
      "Epoch 12/200\n",
      "0s - loss: 0.1448 - val_loss: 0.2159\n",
      "Epoch 13/200\n",
      "0s - loss: 0.1484 - val_loss: 0.2235\n",
      "Epoch 14/200\n",
      "0s - loss: 0.1538 - val_loss: 0.2282\n",
      "Epoch 15/200\n",
      "0s - loss: 0.1581 - val_loss: 0.2301\n",
      "Epoch 16/200\n",
      "0s - loss: 0.1602 - val_loss: 0.2293\n",
      "Epoch 17/200\n",
      "0s - loss: 0.1598 - val_loss: 0.2265\n",
      "Epoch 18/200\n",
      "0s - loss: 0.1572 - val_loss: 0.2221\n",
      "Epoch 19/200\n",
      "0s - loss: 0.1534 - val_loss: 0.2169\n",
      "Epoch 20/200\n",
      "0s - loss: 0.1494 - val_loss: 0.2114\n",
      "Epoch 21/200\n",
      "0s - loss: 0.1459 - val_loss: 0.2063\n",
      "Epoch 22/200\n",
      "0s - loss: 0.1435 - val_loss: 0.2021\n",
      "Epoch 23/200\n",
      "0s - loss: 0.1420 - val_loss: 0.1989\n",
      "Epoch 24/200\n",
      "0s - loss: 0.1411 - val_loss: 0.1966\n",
      "Epoch 25/200\n",
      "0s - loss: 0.1403 - val_loss: 0.1951\n",
      "Epoch 26/200\n",
      "0s - loss: 0.1396 - val_loss: 0.1944\n",
      "Epoch 27/200\n",
      "0s - loss: 0.1389 - val_loss: 0.1943\n",
      "Epoch 28/200\n",
      "0s - loss: 0.1384 - val_loss: 0.1946\n",
      "Epoch 29/200\n",
      "0s - loss: 0.1380 - val_loss: 0.1951\n",
      "Epoch 30/200\n",
      "0s - loss: 0.1377 - val_loss: 0.1956\n",
      "Epoch 31/200\n",
      "0s - loss: 0.1376 - val_loss: 0.1960\n",
      "Epoch 32/200\n",
      "0s - loss: 0.1375 - val_loss: 0.1961\n",
      "Epoch 33/200\n",
      "0s - loss: 0.1374 - val_loss: 0.1959\n",
      "Epoch 34/200\n",
      "0s - loss: 0.1373 - val_loss: 0.1951\n",
      "Epoch 35/200\n",
      "0s - loss: 0.1370 - val_loss: 0.1936\n",
      "Epoch 36/200\n",
      "0s - loss: 0.1365 - val_loss: 0.1920\n",
      "Epoch 37/200\n",
      "0s - loss: 0.1359 - val_loss: 0.1906\n",
      "Epoch 38/200\n",
      "0s - loss: 0.1354 - val_loss: 0.1896\n",
      "Epoch 39/200\n",
      "0s - loss: 0.1350 - val_loss: 0.1890\n",
      "Epoch 40/200\n",
      "0s - loss: 0.1348 - val_loss: 0.1885\n",
      "Epoch 41/200\n",
      "0s - loss: 0.1346 - val_loss: 0.1879\n",
      "Epoch 42/200\n",
      "0s - loss: 0.1344 - val_loss: 0.1871\n",
      "Epoch 43/200\n",
      "0s - loss: 0.1341 - val_loss: 0.1862\n",
      "Epoch 44/200\n",
      "0s - loss: 0.1338 - val_loss: 0.1853\n",
      "Epoch 45/200\n",
      "0s - loss: 0.1336 - val_loss: 0.1844\n",
      "Epoch 46/200\n",
      "0s - loss: 0.1333 - val_loss: 0.1835\n",
      "Epoch 47/200\n",
      "0s - loss: 0.1330 - val_loss: 0.1828\n",
      "Epoch 48/200\n",
      "0s - loss: 0.1327 - val_loss: 0.1824\n",
      "Epoch 49/200\n",
      "0s - loss: 0.1326 - val_loss: 0.1822\n",
      "Epoch 50/200\n",
      "0s - loss: 0.1325 - val_loss: 0.1816\n",
      "Epoch 51/200\n",
      "0s - loss: 0.1323 - val_loss: 0.1807\n",
      "Epoch 52/200\n",
      "0s - loss: 0.1320 - val_loss: 0.1797\n",
      "Epoch 53/200\n",
      "0s - loss: 0.1317 - val_loss: 0.1789\n",
      "Epoch 54/200\n",
      "0s - loss: 0.1314 - val_loss: 0.1784\n",
      "Epoch 55/200\n",
      "0s - loss: 0.1312 - val_loss: 0.1778\n",
      "Epoch 56/200\n",
      "0s - loss: 0.1310 - val_loss: 0.1773\n",
      "Epoch 57/200\n",
      "0s - loss: 0.1309 - val_loss: 0.1769\n",
      "Epoch 58/200\n",
      "0s - loss: 0.1307 - val_loss: 0.1764\n",
      "Epoch 59/200\n",
      "0s - loss: 0.1306 - val_loss: 0.1759\n",
      "Epoch 60/200\n",
      "0s - loss: 0.1304 - val_loss: 0.1756\n",
      "Epoch 61/200\n",
      "0s - loss: 0.1303 - val_loss: 0.1753\n",
      "Epoch 62/200\n",
      "0s - loss: 0.1302 - val_loss: 0.1748\n",
      "Epoch 63/200\n",
      "0s - loss: 0.1300 - val_loss: 0.1743\n",
      "Epoch 64/200\n",
      "0s - loss: 0.1299 - val_loss: 0.1740\n",
      "Epoch 65/200\n",
      "0s - loss: 0.1298 - val_loss: 0.1738\n",
      "Epoch 66/200\n",
      "0s - loss: 0.1297 - val_loss: 0.1734\n",
      "Epoch 67/200\n",
      "0s - loss: 0.1296 - val_loss: 0.1729\n",
      "Epoch 68/200\n",
      "0s - loss: 0.1294 - val_loss: 0.1725\n",
      "Epoch 69/200\n",
      "0s - loss: 0.1293 - val_loss: 0.1723\n",
      "Epoch 70/200\n",
      "0s - loss: 0.1292 - val_loss: 0.1720\n",
      "Epoch 71/200\n",
      "0s - loss: 0.1292 - val_loss: 0.1714\n",
      "Epoch 72/200\n",
      "0s - loss: 0.1290 - val_loss: 0.1708\n",
      "Epoch 73/200\n",
      "0s - loss: 0.1288 - val_loss: 0.1704\n",
      "Epoch 74/200\n",
      "0s - loss: 0.1287 - val_loss: 0.1701\n",
      "Epoch 75/200\n",
      "0s - loss: 0.1286 - val_loss: 0.1700\n",
      "Epoch 76/200\n",
      "0s - loss: 0.1285 - val_loss: 0.1699\n",
      "Epoch 77/200\n",
      "0s - loss: 0.1285 - val_loss: 0.1697\n",
      "Epoch 78/200\n",
      "0s - loss: 0.1285 - val_loss: 0.1691\n",
      "Epoch 79/200\n",
      "0s - loss: 0.1283 - val_loss: 0.1685\n",
      "Epoch 80/200\n",
      "0s - loss: 0.1281 - val_loss: 0.1680\n",
      "Epoch 81/200\n",
      "0s - loss: 0.1280 - val_loss: 0.1679\n",
      "Epoch 82/200\n",
      "0s - loss: 0.1279 - val_loss: 0.1678\n",
      "Epoch 83/200\n",
      "0s - loss: 0.1279 - val_loss: 0.1675\n",
      "Epoch 84/200\n",
      "0s - loss: 0.1278 - val_loss: 0.1673\n",
      "Epoch 85/200\n",
      "0s - loss: 0.1277 - val_loss: 0.1672\n",
      "Epoch 86/200\n",
      "0s - loss: 0.1276 - val_loss: 0.1671\n",
      "Epoch 87/200\n",
      "0s - loss: 0.1276 - val_loss: 0.1669\n",
      "Epoch 88/200\n",
      "0s - loss: 0.1275 - val_loss: 0.1668\n",
      "Epoch 89/200\n",
      "0s - loss: 0.1274 - val_loss: 0.1669\n",
      "Epoch 90/200\n",
      "0s - loss: 0.1274 - val_loss: 0.1668\n",
      "Epoch 91/200\n",
      "0s - loss: 0.1274 - val_loss: 0.1664\n",
      "Epoch 92/200\n",
      "0s - loss: 0.1273 - val_loss: 0.1662\n",
      "Epoch 93/200\n",
      "0s - loss: 0.1271 - val_loss: 0.1662\n",
      "Epoch 94/200\n",
      "0s - loss: 0.1271 - val_loss: 0.1660\n",
      "Epoch 95/200\n",
      "0s - loss: 0.1271 - val_loss: 0.1656\n",
      "Epoch 96/200\n",
      "0s - loss: 0.1269 - val_loss: 0.1655\n",
      "Epoch 97/200\n",
      "0s - loss: 0.1268 - val_loss: 0.1654\n",
      "Epoch 98/200\n",
      "0s - loss: 0.1268 - val_loss: 0.1652\n",
      "Epoch 99/200\n",
      "0s - loss: 0.1267 - val_loss: 0.1651\n",
      "Epoch 100/200\n",
      "0s - loss: 0.1266 - val_loss: 0.1648\n",
      "Epoch 101/200\n",
      "0s - loss: 0.1265 - val_loss: 0.1645\n",
      "Epoch 102/200\n",
      "0s - loss: 0.1264 - val_loss: 0.1643\n",
      "Epoch 103/200\n",
      "0s - loss: 0.1262 - val_loss: 0.1642\n",
      "Epoch 104/200\n",
      "0s - loss: 0.1262 - val_loss: 0.1640\n",
      "Epoch 105/200\n",
      "0s - loss: 0.1261 - val_loss: 0.1637\n",
      "Epoch 106/200\n",
      "0s - loss: 0.1260 - val_loss: 0.1636\n",
      "Epoch 107/200\n",
      "0s - loss: 0.1259 - val_loss: 0.1633\n",
      "Epoch 108/200\n",
      "0s - loss: 0.1258 - val_loss: 0.1630\n",
      "Epoch 109/200\n",
      "0s - loss: 0.1257 - val_loss: 0.1627\n",
      "Epoch 110/200\n",
      "0s - loss: 0.1255 - val_loss: 0.1624\n",
      "Epoch 111/200\n",
      "0s - loss: 0.1255 - val_loss: 0.1621\n",
      "Epoch 112/200\n",
      "0s - loss: 0.1253 - val_loss: 0.1620\n",
      "Epoch 113/200\n",
      "0s - loss: 0.1252 - val_loss: 0.1618\n",
      "Epoch 114/200\n",
      "0s - loss: 0.1252 - val_loss: 0.1614\n",
      "Epoch 115/200\n",
      "0s - loss: 0.1251 - val_loss: 0.1610\n",
      "Epoch 116/200\n",
      "0s - loss: 0.1249 - val_loss: 0.1608\n",
      "Epoch 117/200\n",
      "0s - loss: 0.1248 - val_loss: 0.1607\n",
      "Epoch 118/200\n",
      "0s - loss: 0.1248 - val_loss: 0.1604\n",
      "Epoch 119/200\n",
      "0s - loss: 0.1248 - val_loss: 0.1599\n",
      "Epoch 120/200\n",
      "0s - loss: 0.1245 - val_loss: 0.1594\n",
      "Epoch 121/200\n",
      "0s - loss: 0.1244 - val_loss: 0.1589\n",
      "Epoch 122/200\n",
      "0s - loss: 0.1242 - val_loss: 0.1585\n",
      "Epoch 123/200\n",
      "0s - loss: 0.1241 - val_loss: 0.1582\n",
      "Epoch 124/200\n",
      "0s - loss: 0.1240 - val_loss: 0.1579\n",
      "Epoch 125/200\n",
      "0s - loss: 0.1239 - val_loss: 0.1578\n",
      "Epoch 126/200\n",
      "0s - loss: 0.1238 - val_loss: 0.1576\n",
      "Epoch 127/200\n",
      "0s - loss: 0.1238 - val_loss: 0.1574\n",
      "Epoch 128/200\n",
      "0s - loss: 0.1238 - val_loss: 0.1571\n",
      "Epoch 129/200\n",
      "0s - loss: 0.1237 - val_loss: 0.1567\n",
      "Epoch 130/200\n",
      "0s - loss: 0.1236 - val_loss: 0.1563\n",
      "Epoch 131/200\n",
      "0s - loss: 0.1235 - val_loss: 0.1559\n",
      "Epoch 132/200\n",
      "0s - loss: 0.1235 - val_loss: 0.1557\n",
      "Epoch 133/200\n",
      "0s - loss: 0.1234 - val_loss: 0.1556\n",
      "Epoch 134/200\n",
      "0s - loss: 0.1234 - val_loss: 0.1554\n",
      "Epoch 135/200\n",
      "0s - loss: 0.1233 - val_loss: 0.1551\n",
      "Epoch 136/200\n",
      "0s - loss: 0.1233 - val_loss: 0.1547\n",
      "Epoch 137/200\n",
      "0s - loss: 0.1232 - val_loss: 0.1543\n",
      "Epoch 138/200\n",
      "0s - loss: 0.1231 - val_loss: 0.1539\n",
      "Epoch 139/200\n",
      "0s - loss: 0.1231 - val_loss: 0.1536\n",
      "Epoch 140/200\n",
      "0s - loss: 0.1230 - val_loss: 0.1533\n",
      "Epoch 141/200\n",
      "0s - loss: 0.1229 - val_loss: 0.1530\n",
      "Epoch 142/200\n",
      "0s - loss: 0.1229 - val_loss: 0.1528\n",
      "Epoch 143/200\n",
      "0s - loss: 0.1228 - val_loss: 0.1525\n",
      "Epoch 144/200\n",
      "0s - loss: 0.1228 - val_loss: 0.1522\n",
      "Epoch 145/200\n",
      "0s - loss: 0.1228 - val_loss: 0.1518\n",
      "Epoch 146/200\n",
      "0s - loss: 0.1227 - val_loss: 0.1514\n",
      "Epoch 147/200\n",
      "0s - loss: 0.1226 - val_loss: 0.1510\n",
      "Epoch 148/200\n",
      "0s - loss: 0.1225 - val_loss: 0.1507\n",
      "Epoch 149/200\n",
      "0s - loss: 0.1225 - val_loss: 0.1504\n",
      "Epoch 150/200\n",
      "0s - loss: 0.1224 - val_loss: 0.1504\n",
      "Epoch 151/200\n",
      "0s - loss: 0.1224 - val_loss: 0.1503\n",
      "Epoch 152/200\n",
      "0s - loss: 0.1223 - val_loss: 0.1500\n",
      "Epoch 153/200\n",
      "0s - loss: 0.1222 - val_loss: 0.1501\n",
      "Epoch 154/200\n",
      "0s - loss: 0.1221 - val_loss: 0.1504\n",
      "Epoch 155/200\n",
      "0s - loss: 0.1222 - val_loss: 0.1506\n",
      "Epoch 156/200\n",
      "0s - loss: 0.1223 - val_loss: 0.1508\n",
      "Epoch 157/200\n",
      "0s - loss: 0.1222 - val_loss: 0.1509\n",
      "Epoch 158/200\n",
      "0s - loss: 0.1221 - val_loss: 0.1511\n",
      "Epoch 159/200\n",
      "0s - loss: 0.1221 - val_loss: 0.1515\n",
      "Epoch 160/200\n",
      "0s - loss: 0.1221 - val_loss: 0.1517\n",
      "Epoch 161/200\n",
      "0s - loss: 0.1221 - val_loss: 0.1517\n",
      "Epoch 162/200\n",
      "0s - loss: 0.1220 - val_loss: 0.1518\n",
      "Epoch 163/200\n",
      "0s - loss: 0.1220 - val_loss: 0.1519\n",
      "Epoch 164/200\n",
      "0s - loss: 0.1220 - val_loss: 0.1521\n",
      "Epoch 165/200\n",
      "0s - loss: 0.1219 - val_loss: 0.1522\n",
      "Epoch 166/200\n",
      "0s - loss: 0.1219 - val_loss: 0.1523\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.1218 - val_loss: 0.1524\n",
      "Epoch 168/200\n",
      "0s - loss: 0.1218 - val_loss: 0.1524\n",
      "Epoch 169/200\n",
      "0s - loss: 0.1218 - val_loss: 0.1524\n",
      "Epoch 170/200\n",
      "0s - loss: 0.1217 - val_loss: 0.1524\n",
      "Epoch 171/200\n",
      "0s - loss: 0.1217 - val_loss: 0.1523\n",
      "Epoch 172/200\n",
      "0s - loss: 0.1216 - val_loss: 0.1523\n",
      "Epoch 173/200\n",
      "0s - loss: 0.1215 - val_loss: 0.1526\n",
      "Epoch 174/200\n",
      "0s - loss: 0.1215 - val_loss: 0.1528\n",
      "Epoch 175/200\n",
      "0s - loss: 0.1215 - val_loss: 0.1531\n",
      "Epoch 176/200\n",
      "0s - loss: 0.1215 - val_loss: 0.1530\n",
      "Epoch 177/200\n",
      "0s - loss: 0.1215 - val_loss: 0.1527\n",
      "Epoch 178/200\n",
      "0s - loss: 0.1213 - val_loss: 0.1527\n",
      "Epoch 179/200\n",
      "0s - loss: 0.1212 - val_loss: 0.1527\n",
      "Epoch 180/200\n",
      "0s - loss: 0.1211 - val_loss: 0.1530\n",
      "Epoch 181/200\n",
      "0s - loss: 0.1211 - val_loss: 0.1533\n",
      "Epoch 182/200\n",
      "0s - loss: 0.1211 - val_loss: 0.1537\n",
      "Epoch 183/200\n",
      "0s - loss: 0.1211 - val_loss: 0.1543\n",
      "Epoch 184/200\n",
      "0s - loss: 0.1211 - val_loss: 0.1546\n",
      "Epoch 185/200\n",
      "0s - loss: 0.1212 - val_loss: 0.1546\n",
      "Epoch 186/200\n",
      "0s - loss: 0.1212 - val_loss: 0.1545\n",
      "Epoch 187/200\n",
      "0s - loss: 0.1210 - val_loss: 0.1545\n",
      "Epoch 188/200\n",
      "0s - loss: 0.1209 - val_loss: 0.1547\n",
      "Epoch 189/200\n",
      "0s - loss: 0.1209 - val_loss: 0.1549\n",
      "Epoch 190/200\n",
      "0s - loss: 0.1209 - val_loss: 0.1552\n",
      "Epoch 191/200\n",
      "0s - loss: 0.1209 - val_loss: 0.1555\n",
      "Epoch 192/200\n",
      "0s - loss: 0.1209 - val_loss: 0.1557\n",
      "Epoch 193/200\n",
      "0s - loss: 0.1208 - val_loss: 0.1558\n",
      "Epoch 194/200\n",
      "0s - loss: 0.1208 - val_loss: 0.1559\n",
      "Epoch 195/200\n",
      "0s - loss: 0.1207 - val_loss: 0.1561\n",
      "Epoch 196/200\n",
      "0s - loss: 0.1207 - val_loss: 0.1564\n",
      "Epoch 197/200\n",
      "0s - loss: 0.1207 - val_loss: 0.1567\n",
      "Epoch 198/200\n",
      "0s - loss: 0.1207 - val_loss: 0.1569\n",
      "Epoch 199/200\n",
      "0s - loss: 0.1207 - val_loss: 0.1570\n",
      "Epoch 200/200\n",
      "0s - loss: 0.1206 - val_loss: 0.1571\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec75a7db70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (18,8) (3,) (18,8) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-486800f0b0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# invert scaling for forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0minv_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0minv_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_yhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0minv_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_yhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# invert scaling for actual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEPRECATION_MSG_1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (18,8) (3,) (18,8) "
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# load dataset\n",
    "#dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "\n",
    "dataset = df[[\"IPCA\", \"IGPM\", \"SELIC\"]]\n",
    "\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "#encoder = LabelEncoder()\n",
    "#values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# specify the number of lag hours\n",
    "n_steps = 3\n",
    "n_features = 3\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_steps, 1)\n",
    "print(reframed.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train = 100\n",
    "train = values[:n_train, :]\n",
    "test = values[n_train:, :]\n",
    "# split into input and outputs\n",
    "n_obs = n_steps * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_steps, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_steps, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=200, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_steps*n_features))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, -7:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -7:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44,  0.5 ,  1.08],\n",
       "       [ 0.44,  0.27,  0.87],\n",
       "       [ 0.37,  0.34,  1.05],\n",
       "       [ 0.25,  0.04,  0.94],\n",
       "       [ 0.28,  0.04,  1.03],\n",
       "       [ 0.28,  0.26,  0.91],\n",
       "       [ 0.24,  0.28,  0.97],\n",
       "       [ 0.47,  0.98,  0.99],\n",
       "       [ 0.18,  1.29,  0.8 ],\n",
       "       [ 0.3 ,  1.05,  0.93],\n",
       "       [ 0.38,  0.69,  0.84],\n",
       "       [ 0.74,  1.76,  0.84],\n",
       "       [ 0.54,  1.09,  0.93],\n",
       "       [ 0.49,  0.53,  0.8 ],\n",
       "       [ 0.48,  0.74,  0.84],\n",
       "       [ 0.55,  0.69,  0.9 ],\n",
       "       [ 0.79,  1.61,  0.88],\n",
       "       [ 0.74,  1.98,  0.96],\n",
       "       [ 0.53,  1.76,  1.07],\n",
       "       [ 0.28, -0.32,  1.02],\n",
       "       [ 0.26,  0.11,  1.1 ],\n",
       "       [ 0.45,  0.98,  1.18],\n",
       "       [ 0.36,  0.38,  1.02],\n",
       "       [ 0.28, -0.13,  1.12],\n",
       "       [ 0.48, -0.44,  1.05],\n",
       "       [ 0.55,  0.26,  0.86],\n",
       "       [ 0.2 , -0.74,  0.97],\n",
       "       [ 0.48, -0.15,  0.84],\n",
       "       [ 0.47, -0.07,  0.77],\n",
       "       [ 0.36, -0.1 ,  0.76],\n",
       "       [ 0.24, -0.43,  0.79],\n",
       "       [ 0.15, -0.36,  0.69],\n",
       "       [ 0.24,  0.42,  0.69],\n",
       "       [ 0.28,  0.05,  0.69],\n",
       "       [ 0.41,  0.1 ,  0.66],\n",
       "       [ 0.37, -0.26,  0.73],\n",
       "       [ 0.75,  0.63,  0.66],\n",
       "       [ 0.78,  1.18,  0.59],\n",
       "       [ 0.52,  0.94,  0.76],\n",
       "       [ 0.57,  0.77,  0.67],\n",
       "       [ 0.43,  1.19,  0.75],\n",
       "       [ 0.  ,  0.85,  0.79],\n",
       "       [ 0.01,  0.15,  0.86],\n",
       "       [ 0.04,  0.77,  0.89],\n",
       "       [ 0.45,  1.15,  0.85],\n",
       "       [ 0.75,  1.01,  0.81],\n",
       "       [ 0.83,  1.45,  0.81],\n",
       "       [ 0.63,  0.69,  0.93],\n",
       "       [ 0.83,  0.79,  0.86],\n",
       "       [ 0.8 ,  1.  ,  0.84],\n",
       "       [ 0.79,  0.62,  0.92],\n",
       "       [ 0.77,  0.45,  0.84],\n",
       "       [ 0.47,  0.43,  0.99],\n",
       "       [ 0.15, -0.18,  0.96],\n",
       "       [ 0.16, -0.12,  0.97],\n",
       "       [ 0.37,  0.44,  1.07],\n",
       "       [ 0.53,  0.65,  0.94],\n",
       "       [ 0.43,  0.53,  0.88],\n",
       "       [ 0.52,  0.5 ,  0.86],\n",
       "       [ 0.5 , -0.12,  0.91],\n",
       "       [ 0.56,  0.25,  0.89],\n",
       "       [ 0.45, -0.06,  0.75],\n",
       "       [ 0.21,  0.43,  0.82],\n",
       "       [ 0.64,  0.85,  0.71],\n",
       "       [ 0.36,  1.02,  0.74],\n",
       "       [ 0.08,  0.66,  0.64],\n",
       "       [ 0.43,  1.34,  0.68],\n",
       "       [ 0.41,  1.43,  0.69],\n",
       "       [ 0.57,  0.97,  0.54],\n",
       "       [ 0.59,  0.02,  0.61],\n",
       "       [ 0.6 , -0.03,  0.55],\n",
       "       [ 0.79,  0.68,  0.55],\n",
       "       [ 0.86,  0.34,  0.6 ],\n",
       "       [ 0.6 ,  0.29,  0.49],\n",
       "       [ 0.47,  0.21,  0.55],\n",
       "       [ 0.55,  0.15,  0.61],\n",
       "       [ 0.37,  0.  ,  0.6 ],\n",
       "       [ 0.26,  0.75,  0.61],\n",
       "       [ 0.03,  0.26,  0.72],\n",
       "       [ 0.24,  0.15,  0.71],\n",
       "       [ 0.35,  1.5 ,  0.71],\n",
       "       [ 0.57,  0.86,  0.81],\n",
       "       [ 0.54,  0.29,  0.72],\n",
       "       [ 0.92,  0.6 ,  0.79],\n",
       "       [ 0.55,  0.48,  0.85],\n",
       "       [ 0.69,  0.38,  0.79],\n",
       "       [ 0.92,  1.67,  0.77],\n",
       "       [ 0.67,  0.78,  0.82],\n",
       "       [ 0.46, -0.13,  0.87],\n",
       "       [ 0.4 , -0.74,  0.82],\n",
       "       [ 0.01, -0.61,  0.95],\n",
       "       [ 0.25, -0.27,  0.87],\n",
       "       [ 0.57,  0.2 ,  0.91],\n",
       "       [ 0.42,  0.28,  0.95],\n",
       "       [ 0.51,  0.98,  0.84],\n",
       "       [ 0.78,  0.62,  0.96],\n",
       "       [ 1.24,  0.76,  0.94],\n",
       "       [ 1.22,  0.27,  0.82],\n",
       "       [ 1.32,  0.98,  1.04],\n",
       "       [ 0.71,  1.17,  0.95],\n",
       "       [ 0.74,  0.41,  0.99],\n",
       "       [ 0.79,  0.67,  1.07],\n",
       "       [ 0.62,  0.69,  1.18],\n",
       "       [ 0.22,  0.28,  1.11],\n",
       "       [ 0.54,  0.95,  1.11],\n",
       "       [ 0.82,  1.89,  1.11],\n",
       "       [ 1.01,  1.52,  1.06],\n",
       "       [ 0.96,  0.49,  1.16],\n",
       "       [ 1.27,  1.14,  1.06],\n",
       "       [ 0.9 ,  1.29,  1.  ],\n",
       "       [ 0.43,  0.51,  1.16],\n",
       "       [ 0.61,  0.33,  1.06],\n",
       "       [ 0.78,  0.82,  1.11],\n",
       "       [ 0.35,  1.69,  1.16],\n",
       "       [ 0.52,  0.18,  1.11],\n",
       "       [ 0.44,  0.15,  1.22],\n",
       "       [ 0.08,  0.2 ,  1.11],\n",
       "       [ 0.26,  0.16,  1.05],\n",
       "       [ 0.18, -0.03,  1.04],\n",
       "       [ 0.3 ,  0.54,  1.12],\n",
       "       [ 0.38,  0.64,  1.09]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12977867,  0.35294122,  0.24590163, ...,  0.        ,\n",
       "         0.        ,  0.14889336],\n",
       "       [ 0.14889336,  0.36764708,  0.24590163, ...,  0.        ,\n",
       "         0.        ,  0.15995975],\n",
       "       [ 0.15995975,  0.42647061,  0.22950819, ...,  0.        ,\n",
       "         0.        ,  0.18209255],\n",
       "       ..., \n",
       "       [ 0.        ,  0.32352942,  0.22950819, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.32352942,  0.16393442, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.33823532,  0.1967213 , ...,  0.        ,\n",
       "         0.        ,  0.0362173 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35039"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
